{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "(60, 1258)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oliver/Repositories/CodeA/stockenv/lib/python3.5/site-packages/sklearn/covariance/graph_lasso_.py:54: RuntimeWarning: invalid value encountered in absolute\n",
      "  - np.abs(np.diag(precision_)).sum())\n",
      "/home/oliver/Repositories/CodeA/stockenv/lib/python3.5/site-packages/numpy/linalg/linalg.py:1712: RuntimeWarning: invalid value encountered in slogdet\n",
      "  sign, logdet = _umath_linalg.slogdet(a, signature=signature)\n",
      "/home/oliver/Repositories/CodeA/stockenv/lib/python3.5/site-packages/sklearn/covariance/graph_lasso_.py:41: RuntimeWarning: invalid value encountered in absolute\n",
      "  - np.abs(np.diag(precision_)).sum())\n",
      "/home/oliver/Repositories/CodeA/stockenv/lib/python3.5/site-packages/sklearn/covariance/graph_lasso_.py:244: RuntimeWarning: invalid value encountered in absolute\n",
      "  if np.abs(d_gap) < tol:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 1: Novartis, Sanofi-Aventis, GlaxoSmithKline\n",
      "Cluster 2: Northrop Grumman, Lookheed Martin, Boeing, Raytheon, General Dynamics\n",
      "Cluster 3: Canon, Honda, Mitsubishi, Toyota, Xerox, Caterpillar, Sony, Unilever, Navistar, Marriott\n",
      "Cluster 4: Procter Gamble, Kimberly-Clark, Colgate-Palmolive\n",
      "Cluster 5: Total, ConocoPhillips, Valero Energy, Chevron, Exxon\n",
      "Cluster 6: Wal-Mart, Home Depot, Wells Fargo, Mc Donalds, AIG, Ford, Goldman Sachs, General Electrics, DuPont de Nemours, JPMorgan Chase, Pfizer, Bank of America, Ryder, American express\n",
      "Cluster 7: Kraft Foods\n",
      "Cluster 8: Yahoo, Amazon, Apple\n",
      "Cluster 9: Texas instruments, Cisco, HP, Dell, SAP, Microsoft, 3M, IBM\n",
      "Cluster 10: Time Warner, Comcast, Cablevision\n",
      "Cluster 11: CVS, Walgreen\n",
      "Cluster 12: Coca Cola, Kellogg, Pepsi\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "# Author: Gael Varoquaux gael.varoquaux@normalesup.org\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "try:\n",
    "    from matplotlib.finance import quotes_historical_yahoo\n",
    "except ImportError:\n",
    "    from matplotlib.finance import quotes_historical_yahoo_ochl as quotes_historical_yahoo\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "from sklearn import cluster, covariance, manifold\n",
    "\n",
    "###############################################################################\n",
    "# Retrieve the data from Internet\n",
    "\n",
    "# Choose a time period reasonnably calm (not too long ago so that we get\n",
    "# high-tech firms, and before the 2008 crash)\n",
    "d1 = datetime.datetime(2003, 1, 1)\n",
    "d2 = datetime.datetime(2008, 1, 1)\n",
    "\n",
    "# kraft symbol has now changed from KFT to MDLZ in yahoo\n",
    "symbol_dict = {\n",
    "    'TOT': 'Total',\n",
    "    'XOM': 'Exxon',\n",
    "    'CVX': 'Chevron',\n",
    "    'COP': 'ConocoPhillips',\n",
    "    'VLO': 'Valero Energy',\n",
    "    'MSFT': 'Microsoft',\n",
    "    'IBM': 'IBM',\n",
    "    'TWX': 'Time Warner',\n",
    "    'CMCSA': 'Comcast',\n",
    "    'CVC': 'Cablevision',\n",
    "    'YHOO': 'Yahoo',\n",
    "    'DELL': 'Dell',\n",
    "    'HPQ': 'HP',\n",
    "    'AMZN': 'Amazon',\n",
    "    'TM': 'Toyota',\n",
    "    'CAJ': 'Canon',\n",
    "    'MTU': 'Mitsubishi',\n",
    "    'SNE': 'Sony',\n",
    "    'F': 'Ford',\n",
    "    'HMC': 'Honda',\n",
    "    'NAV': 'Navistar',\n",
    "    'NOC': 'Northrop Grumman',\n",
    "    'BA': 'Boeing',\n",
    "    'KO': 'Coca Cola',\n",
    "    'MMM': '3M',\n",
    "    'MCD': 'Mc Donalds',\n",
    "    'PEP': 'Pepsi',\n",
    "    'MDLZ': 'Kraft Foods',\n",
    "    'K': 'Kellogg',\n",
    "    'UN': 'Unilever',\n",
    "    'MAR': 'Marriott',\n",
    "    'PG': 'Procter Gamble',\n",
    "    'CL': 'Colgate-Palmolive',\n",
    "    'GE': 'General Electrics',\n",
    "    'WFC': 'Wells Fargo',\n",
    "    'JPM': 'JPMorgan Chase',\n",
    "    'AIG': 'AIG',\n",
    "    'AXP': 'American express',\n",
    "    'BAC': 'Bank of America',\n",
    "    'GS': 'Goldman Sachs',\n",
    "    'AAPL': 'Apple',\n",
    "    'SAP': 'SAP',\n",
    "    'CSCO': 'Cisco',\n",
    "    'TXN': 'Texas instruments',\n",
    "    'XRX': 'Xerox',\n",
    "    'LMT': 'Lookheed Martin',\n",
    "    'WMT': 'Wal-Mart',\n",
    "    'WBA': 'Walgreen',\n",
    "    'HD': 'Home Depot',\n",
    "    'GSK': 'GlaxoSmithKline',\n",
    "    'PFE': 'Pfizer',\n",
    "    'SNY': 'Sanofi-Aventis',\n",
    "    'NVS': 'Novartis',\n",
    "    'KMB': 'Kimberly-Clark',\n",
    "    'R': 'Ryder',\n",
    "    'GD': 'General Dynamics',\n",
    "    'RTN': 'Raytheon',\n",
    "    'CVS': 'CVS',\n",
    "    'CAT': 'Caterpillar',\n",
    "    'DD': 'DuPont de Nemours'}\n",
    "\n",
    "symbols, names = np.array(list(symbol_dict.items())).T\n",
    "\n",
    "quotes = [quotes_historical_yahoo(symbol, d1, d2, asobject=True)\n",
    "          for symbol in symbols]\n",
    "\n",
    "open = np.array([q.open for q in quotes]).astype(np.float)\n",
    "close = np.array([q.close for q in quotes]).astype(np.float)\n",
    "\n",
    "print(close.shape)\n",
    "\n",
    "# The daily variations of the quotes are what carry most information\n",
    "variation = close - open\n",
    "\n",
    "###############################################################################\n",
    "# Learn a graphical structure from the correlations\n",
    "edge_model = covariance.GraphLassoCV()\n",
    "\n",
    "# standardize the time series: using correlations rather than covariance\n",
    "# is more efficient for structure recovery\n",
    "X = variation.copy().T\n",
    "X /= X.std(axis=0)\n",
    "edge_model.fit(X)\n",
    "\n",
    "###############################################################################\n",
    "# Cluster using affinity propagation\n",
    "\n",
    "_, labels = cluster.affinity_propagation(edge_model.covariance_)\n",
    "n_labels = labels.max()\n",
    "\n",
    "for i in range(n_labels + 1):\n",
    "    print('Cluster %i: %s' % ((i + 1), ', '.join(names[labels == i])))\n",
    "\n",
    "###############################################################################\n",
    "# Find a low-dimension embedding for visualization: find the best position of\n",
    "# the nodes (the stocks) on a 2D plane\n",
    "\n",
    "# We use a dense eigen_solver to achieve reproducibility (arpack is\n",
    "# initiated with random vectors that we don't control). In addition, we\n",
    "# use a large number of neighbors to capture the large-scale structure.\n",
    "node_position_model = manifold.LocallyLinearEmbedding(\n",
    "    n_components=2, eigen_solver='dense', n_neighbors=6)\n",
    "\n",
    "embedding = node_position_model.fit_transform(X.T).T\n",
    "\n",
    "###############################################################################\n",
    "# Visualization\n",
    "plt.figure(1, facecolor='w', figsize=(10, 8))\n",
    "plt.clf()\n",
    "ax = plt.axes([0., 0., 1., 1.])\n",
    "plt.axis('off')\n",
    "\n",
    "# Display a graph of the partial correlations\n",
    "partial_correlations = edge_model.precision_.copy()\n",
    "d = 1 / np.sqrt(np.diag(partial_correlations))\n",
    "partial_correlations *= d\n",
    "partial_correlations *= d[:, np.newaxis]\n",
    "non_zero = (np.abs(np.triu(partial_correlations, k=1)) > 0.02)\n",
    "\n",
    "# Plot the nodes using the coordinates of our embedding\n",
    "plt.scatter(embedding[0], embedding[1], s=100 * d ** 2, c=labels,\n",
    "            cmap=plt.cm.spectral)\n",
    "\n",
    "# Plot the edges\n",
    "start_idx, end_idx = np.where(non_zero)\n",
    "#a sequence of (*line0*, *line1*, *line2*), where::\n",
    "#            linen = (x0, y0), (x1, y1), ... (xm, ym)\n",
    "segments = [[embedding[:, start], embedding[:, stop]]\n",
    "            for start, stop in zip(start_idx, end_idx)]\n",
    "values = np.abs(partial_correlations[non_zero])\n",
    "lc = LineCollection(segments,\n",
    "                    zorder=0, cmap=plt.cm.hot_r,\n",
    "                    norm=plt.Normalize(0, .7 * values.max()))\n",
    "lc.set_array(values)\n",
    "lc.set_linewidths(15 * values)\n",
    "ax.add_collection(lc)\n",
    "\n",
    "# Add a label to each node. The challenge here is that we want to\n",
    "# position the labels to avoid overlap with other labels\n",
    "for index, (name, label, (x, y)) in enumerate(\n",
    "        zip(names, labels, embedding.T)):\n",
    "\n",
    "    dx = x - embedding[0]\n",
    "    dx[index] = 1\n",
    "    dy = y - embedding[1]\n",
    "    dy[index] = 1\n",
    "    this_dx = dx[np.argmin(np.abs(dy))]\n",
    "    this_dy = dy[np.argmin(np.abs(dx))]\n",
    "    if this_dx > 0:\n",
    "        horizontalalignment = 'left'\n",
    "        x = x + .002\n",
    "    else:\n",
    "        horizontalalignment = 'right'\n",
    "        x = x - .002\n",
    "    if this_dy > 0:\n",
    "        verticalalignment = 'bottom'\n",
    "        y = y + .002\n",
    "    else:\n",
    "        verticalalignment = 'top'\n",
    "        y = y - .002\n",
    "    plt.text(x, y, name, size=10,\n",
    "             horizontalalignment=horizontalalignment,\n",
    "             verticalalignment=verticalalignment,\n",
    "             bbox=dict(facecolor='w',\n",
    "                       edgecolor=plt.cm.spectral(label / float(n_labels)),\n",
    "                       alpha=.6))\n",
    "\n",
    "plt.xlim(embedding[0].min() - .15 * embedding[0].ptp(),\n",
    "         embedding[0].max() + .10 * embedding[0].ptp(),)\n",
    "plt.ylim(embedding[1].min() - .03 * embedding[1].ptp(),\n",
    "         embedding[1].max() + .03 * embedding[1].ptp())\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
